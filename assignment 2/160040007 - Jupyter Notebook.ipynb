{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt.solvers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, kernel=linear_kernel, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None:\n",
    "            self.C = float(self.C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i, j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1, n_samples), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n], sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * self.kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train(X1, y1, X2, y2):\n",
    "    X1_train = X1[:80]\n",
    "    y1_train = y1[:80]\n",
    "    X2_train = X2[:80]\n",
    "    y2_train = y2[:80]\n",
    "    X_train = np.vstack((X1_train, X2_train))\n",
    "    y_train = np.hstack((y1_train, y2_train))\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test(X1, y1, X2, y2):\n",
    "    X1_test = X1[80:]\n",
    "    y1_test = y1[80:]\n",
    "    X2_test = X2[80:]\n",
    "    y2_test = y2[80:]\n",
    "    X_test = np.vstack((X1_test, X2_test))\n",
    "    y_test = np.hstack((y1_test, y2_test))\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Data\n",
    "data = pd.read_csv('creditcard.csv', sep=',', decimal='.')\n",
    "data_arr = data.iloc[:, :].values\n",
    "\n",
    "test1 = data.loc[data['Class'] == 1]\n",
    "test0 = data.loc[data['Class'] == 0]\n",
    "\n",
    "temp1 = test1.sample(n=100)\n",
    "temp0 = test0.sample(n=100)\n",
    "\n",
    "X1 = temp1.iloc[:, 0:-1].values\n",
    "y1 = temp1.iloc[:, -1].values\n",
    "X2 = temp0.iloc[:, 0:-1].values\n",
    "y2 = temp0.iloc[:, -1].values\n",
    "\n",
    "y1[y1 == 0] = -1\n",
    "y2[y2 == 0] = -1\n",
    "\n",
    "X_train, y_train = split_train(X1, y1, X2, y2)\n",
    "X_test, y_test = split_test(X1, y1, X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.9070e+01 -1.1592e+02  7e+02  3e+01  2e+00\n",
      " 1: -1.2242e+02 -1.7358e+02  5e+02  2e+01  1e+00\n",
      " 2: -2.6900e+02 -2.9132e+02  4e+02  1e+01  1e+00\n",
      " 3: -3.5355e+02 -2.9625e+02  4e+02  8e+00  8e-01\n",
      " 4: -2.3766e+02 -1.5325e+02  3e+02  5e+00  4e-01\n",
      " 5: -1.4324e+02 -7.9830e+01  2e+02  3e+00  3e-01\n",
      " 6: -8.2220e+01 -4.6820e+01  1e+02  1e+00  1e-01\n",
      " 7: -4.0948e+01 -3.1333e+01  7e+01  5e-01  5e-02\n",
      " 8: -3.0169e+01 -2.8723e+01  5e+01  3e-01  3e-02\n",
      " 9: -2.6285e+01 -2.6236e+01  3e+01  2e-01  2e-02\n",
      "10: -2.3765e+01 -2.2997e+01  2e+01  1e-01  1e-02\n",
      "11: -2.0353e+01 -1.9844e+01  9e+00  4e-02  4e-03\n",
      "12: -1.7470e+01 -1.8333e+01  3e+00  9e-03  8e-04\n",
      "13: -1.7517e+01 -1.7938e+01  9e-01  2e-03  2e-04\n",
      "14: -1.7782e+01 -1.7816e+01  3e-02  4e-15  5e-05\n",
      "15: -1.7810e+01 -1.7810e+01  6e-04  3e-15  5e-05\n",
      "16: -1.7810e+01 -1.7810e+01  7e-06  2e-15  5e-05\n",
      "17: -1.7810e+01 -1.7810e+01  7e-08  6e-15  5e-05\n",
      "18: -1.7810e+01 -1.7810e+01  7e-10  8e-15  5e-05\n",
      "19: -1.7810e+01 -1.7810e+01  7e-12  5e-15  5e-05\n",
      "20: -1.7810e+01 -1.7810e+01  7e-14  4e-15  4e-05\n",
      "21: -1.7810e+01 -1.7810e+01  7e-16  4e-15  3e-05\n",
      "22: -1.7810e+01 -1.7810e+01  7e-18  1e-15  2e-05\n",
      "23: -1.7810e+01 -1.7810e+01  7e-20  1e-15  2e-05\n",
      "24: -1.7810e+01 -1.7810e+01  7e-22  1e-15  2e-05\n",
      "25: -1.7810e+01 -1.7810e+01  7e-24  2e-15  2e-05\n",
      "26: -1.7810e+01 -1.7810e+01  7e-26  1e-15  2e-05\n",
      "27: -1.7810e+01 -1.7810e+01  7e-28  2e-15  2e-05\n",
      "28: -1.7810e+01 -1.7810e+01  7e-30  2e-15  2e-05\n",
      "29: -1.7810e+01 -1.7810e+01  7e-32  2e-15  2e-05\n",
      "30: -1.7810e+01 -1.7810e+01  7e-34  3e-15  2e-05\n",
      "31: -1.7810e+01 -1.7810e+01  7e-36  3e-15  2e-05\n",
      "32: -1.7810e+01 -1.7810e+01  7e-38  1e-15  2e-05\n",
      "33: -1.7810e+01 -1.7810e+01  7e-40  4e-15  2e-05\n",
      "34: -1.7810e+01 -1.7810e+01  7e-42  1e-15  2e-05\n",
      "35: -1.7810e+01 -1.7810e+01  7e-44  2e-15  2e-05\n",
      "36: -1.7810e+01 -1.7810e+01  7e-46  2e-15  2e-05\n",
      "37: -1.7810e+01 -1.7810e+01  7e-48  2e-15  2e-05\n",
      "38: -1.7810e+01 -1.7810e+01  7e-50  1e-15  2e-05\n",
      "39: -1.7810e+01 -1.7810e+01  7e-52  2e-15  2e-05\n",
      "40: -1.7810e+01 -1.7810e+01  7e-54  2e-15  2e-05\n",
      "41: -1.7810e+01 -1.7810e+01  7e-56  2e-15  2e-05\n",
      "42: -1.7810e+01 -1.7810e+01  7e-58  2e-15  2e-05\n",
      "43: -1.7810e+01 -1.7810e+01  7e-60  3e-15  2e-05\n",
      "44: -1.7810e+01 -1.7810e+01  7e-62  4e-15  2e-05\n",
      "45: -1.7810e+01 -1.7810e+01  7e-64  3e-15  2e-05\n",
      "46: -1.7810e+01 -1.7810e+01  7e-66  2e-15  2e-05\n",
      "47: -1.7810e+01 -1.7810e+01  7e-68  2e-15  2e-05\n",
      "48: -1.7810e+01 -1.7810e+01  7e-70  1e-15  2e-05\n",
      "49: -1.7810e+01 -1.7810e+01  7e-72  1e-15  2e-05\n",
      "50: -1.7810e+01 -1.7810e+01  7e-74  2e-15  2e-05\n",
      "51: -1.7810e+01 -1.7810e+01  7e-76  2e-15  2e-05\n",
      "52: -1.7810e+01 -1.7810e+01  7e-78  2e-15  2e-05\n",
      "53: -1.7810e+01 -1.7810e+01  7e-80  2e-15  2e-05\n",
      "54: -1.7810e+01 -1.7810e+01  7e-82  2e-15  2e-05\n",
      "55: -1.7810e+01 -1.7810e+01  7e-84  3e-15  2e-05\n",
      "56: -1.7810e+01 -1.7810e+01  7e-86  3e-15  2e-05\n",
      "57: -1.7810e+01 -1.7810e+01  7e-88  1e-15  2e-05\n",
      "58: -1.7810e+01 -1.7810e+01  7e-90  2e-15  2e-05\n",
      "59: -1.7810e+01 -1.7810e+01  7e-92  4e-15  2e-05\n",
      "60: -1.7810e+01 -1.7810e+01  7e-94  2e-15  2e-05\n",
      "61: -1.7810e+01 -1.7810e+01  7e-96  5e-15  2e-05\n",
      "62: -1.7810e+01 -1.7810e+01  7e-98  2e-15  2e-05\n",
      "63: -1.7810e+01 -1.7810e+01  7e-100  2e-15  2e-05\n",
      "64: -1.7810e+01 -1.7810e+01  7e-102  2e-15  2e-05\n",
      "65: -1.7810e+01 -1.7810e+01  7e-104  2e-15  2e-05\n",
      "66: -1.7810e+01 -1.7810e+01  7e-106  3e-15  3e-05\n",
      "67: -1.7810e+01 -1.7810e+01  7e-108  2e-15  2e-05\n",
      "68: -1.7810e+01 -1.7810e+01  7e-110  2e-15  2e-05\n",
      "69: -1.7810e+01 -1.7810e+01  7e-112  1e-15  2e-05\n",
      "70: -1.7810e+01 -1.7810e+01  7e-114  3e-15  2e-05\n",
      "71: -1.7810e+01 -1.7810e+01  7e-116  2e-15  2e-05\n",
      "72: -1.7810e+01 -1.7810e+01  7e-118  2e-15  2e-05\n",
      "73: -1.7810e+01 -1.7810e+01  7e-120  2e-15  2e-05\n",
      "74: -1.7810e+01 -1.7810e+01  7e-122  2e-15  2e-05\n",
      "75: -1.7810e+01 -1.7810e+01  7e-124  2e-15  2e-05\n",
      "76: -1.7810e+01 -1.7810e+01  7e-126  2e-15  2e-05\n",
      "77: -1.7810e+01 -1.7810e+01  7e-128  4e-15  2e-05\n",
      "78: -1.7810e+01 -1.7810e+01  7e-130  1e-15  2e-05\n",
      "79: -1.7810e+01 -1.7810e+01  7e-132  1e-15  2e-05\n",
      "80: -1.7810e+01 -1.7810e+01  7e-134  1e-15  2e-05\n",
      "81: -1.7810e+01 -1.7810e+01  7e-136  1e-15  2e-05\n",
      "82: -1.7810e+01 -1.7810e+01  7e-138  1e-15  2e-05\n",
      "83: -1.7810e+01 -1.7810e+01  7e-140  1e-15  2e-05\n",
      "84: -1.7810e+01 -1.7810e+01  7e-142  2e-15  2e-05\n",
      "85: -1.7810e+01 -1.7810e+01  7e-144  1e-15  2e-05\n",
      "86: -1.7810e+01 -1.7810e+01  7e-146  4e-15  2e-05\n",
      "87: -1.7810e+01 -1.7810e+01  7e-148  3e-15  2e-05\n",
      "88: -1.7810e+01 -1.7810e+01  7e-150  2e-15  2e-05\n",
      "89: -1.7810e+01 -1.7810e+01  7e-152  2e-15  2e-05\n",
      "90: -1.7810e+01 -1.7810e+01  7e-154  2e-15  2e-05\n",
      "91: -1.7810e+01 -1.7810e+01  7e-156  1e-15  2e-05\n",
      "92: -1.7810e+01 -1.7810e+01  7e-158  2e-15  2e-05\n",
      "93: -1.7810e+01 -1.7810e+01  7e-160  2e-15  2e-05\n",
      "94: -1.7810e+01 -1.7810e+01  7e-162  2e-15  2e-05\n",
      "95: -1.7810e+01 -1.7810e+01  7e-164  2e-15  2e-05\n",
      "96: -1.7810e+01 -1.7810e+01  7e-166  2e-15  2e-05\n",
      "97: -1.7810e+01 -1.7810e+01  7e-168  4e-15  2e-05\n",
      "98: -1.7810e+01 -1.7810e+01  7e-170  4e-15  2e-05\n",
      "99: -1.7810e+01 -1.7810e+01  7e-172  1e-15  2e-05\n",
      "100: -1.7810e+01 -1.7810e+01  7e-174  2e-15  2e-05\n",
      "Terminated (maximum number of iterations reached).\n",
      "23 support vectors out of 160 points\n"
     ]
    }
   ],
   "source": [
    "clf = SVM()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 of 40 predictions correct\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "correct = np.sum(y_predict == y_test)\n",
    "print(\"%d of %d predictions correct\" % (correct, len(y_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
