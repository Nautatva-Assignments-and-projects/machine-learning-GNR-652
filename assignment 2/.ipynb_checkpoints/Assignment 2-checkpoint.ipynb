{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'g',-1:'r'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            \n",
    "    # train       \n",
    "    def fit(self, data):\n",
    "        self.data = data\n",
    "        opt_dict = {} #Optimization Dictionary { ||w||: [w,b] }\n",
    "\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [-1,-1],\n",
    "                      [1,-1]]\n",
    "        \n",
    "        all_data = []\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      # point of expense:\n",
    "                      self.max_feature_value * 0.001,]\n",
    "        \n",
    "        # extremely expensive\n",
    "        b_range_multiple = 5\n",
    "        # \n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10\n",
    "\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            # we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        # weakest link in the SVM fundamentally\n",
    "                        # SMO attempts to fix this a bit\n",
    "                        # yi(xi.w+b) >= 1\n",
    "                        # \n",
    "                        # #### add a break here later..\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                    found_option = False\n",
    "                                    \n",
    "                        if found_option:\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "                            \n",
    "    def predict(self,features):\n",
    "        # sign(xi.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        # if the classification isn't zero, and we have visualization on, we graph\n",
    "        if classification != 0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*', c=self.colors[classification])\n",
    "        else:\n",
    "            print('featureset',features,'is on the decision boundary')\n",
    "        return classification\n",
    "    \n",
    "    def visualize(self):\n",
    "        #scattering known featuresets.\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        def hyperplane(x,w,b,v):\n",
    "            # v = (w.x+b)\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "        \n",
    "\n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "\n",
    "        # (w.x+b) = 1\n",
    "        # positive support vector hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n",
    "\n",
    "        # (w.x+b) = -1\n",
    "        # negative support vector hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n",
    "\n",
    "        # (w.x+b) = 0\n",
    "        # positive support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]),\n",
    "             \n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the data we are using for SVM\n",
    "svm = Support_Vector_Machine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_us = [[0,10],\n",
    "              [1,3],\n",
    "              [3,4],\n",
    "              [3,5],\n",
    "              [5,5],\n",
    "              [5,6],\n",
    "              [6,-5],\n",
    "              [5,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predict_us:\n",
    "    svm.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
